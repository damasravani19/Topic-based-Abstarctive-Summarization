The automation myth
Robots aren't taking your jobs— and that's the problem 
  Over the past five years, American politics has become obsessed with robots.
   President Obama has   that ATMs and airport check-in kiosks are contributing to high unemployment. Sen. Marco Rubio   that the central challenge of our times is "to ensure that the rise of the machines is not the fall of the worker." A   in the Atlantic asked us to ponder the problems of a world without work. And in the New York Times,   warns that "the job-eating maw of technology now threatens even the nimblest and most expensively educated." The good news is that these concerns are wrong. None of the recent problems in the American economy are due to robots — or, to be more specific about it, due to an accelerating pace of automation. Moreover, even if the pace of automation does speed up in the future, there's no real reason to believe that it will be a problem. The bad news is that these concerns are wrong. Rather than an accelerating pace of automation, we've actually been living through a   in the pace of productivity growth. And that slowdown is a huge problem. Unless it reverses, we'll be waking up soon to find ourselves in a depressing world of longer working years, unmanageable health-care needs, higher taxes, and a public sector starved of needed infrastructure resources. In other words, don't worry that the robots will take your job. Be terrified that they won't. When people hear about robots, they think of science fiction — the  ,  , or the thinking, talking computer that powers the starship Enterprise. All this and more may come to pass some day (who knows?) but the reality of day-to-day change is more mundane. Machines have been replacing humans for hundreds of years. And when it happens to you, it stinks. It stank for small business owners whose photo development shops were driven out of business by digital cameras. It stank for analog graphic designers like my mother who were disemployed by desktop publishing software in the late 1980s. It stank for stevedores who were put out of work by container ships. It stank for weavers put out of work by the spinning jenny. It stank for railroad engineers put out of work by the automobile. But for society as a whole  these were huge leaps forward. Specific individuals did in fact lose jobs and oftentimes ended up with lower wages. But on average, job growth continued and living standards rose. The techno-pessimists often admit this. The problem, they say, is if technology reduces the need for human labor   fast, then society won't have time to adjust, and there will be broad unemployment. Well, again, we can look to the past. Despite the cliché that technology today is progressing faster than ever, the per-worker output of the American economy actually increased at its fastest-ever rate in the quarter century between 1948 and 1973. This is the period in which the spread of refrigerators put milkmen out of work, while the initial adoption of machines to wash clothing and dishes rendered full-time household servants superfluous for the middle class. This was a time when television displaced live theater, and when truck-based delivery upended product distribution networks and rendered many neighborhood retailers obsolete. New interstates bypassed old towns and rail depots. Automatic telephone switches put operators out of work. New fertilizer products derived from wartime research increased per-acre crop yields and reduced the number of laborers needed. So what happened?   
 
 
   Well, people worked less. In 1950 (the first year for which we have records), the average employed person in the United States worked about 1,909 hours. By 1973, that had fallen to 1,797 hours. That's a decline of about 6 percent. It's the equivalent of going from having two weeks of paid vacation per year to having five weeks. Or of going from working 9 to 5 every day to working 9:30 to 5 every day. But there was no overall collapse in employment. The total number of employed people grew by more than 50 percent during this period, keeping up with population growth. Wages rose steadily at a pace of about 2.23 percentage points faster than inflation in the average year. And the growth was widely shared. There were rich people and poor people, of course, but the share of overall national income accruing to the very wealthy was modest and generally falling. The fast pace of automation did mean the only people who could get ahead were those clever enough to invent the new machines or lucky enough to earn them. Individual people lost out at particular moments in time, but on average, the tide rose rapidly and lifted the vast majority of the boats. Today it appears to most people that we are living in a period of immense technological change. A rather small device that I carry in my pocket replaces the telephone that used to sit in my bedroom, the Walkman in my pocket, the TI-85 calculator in my backpack, every single book I've ever owned, the Sega Genesis on the shelf, the alarm clock on my bedside table, and even, to some extent, my television. And yet it doesn't only replicate the functions of those devices. In most cases it far surpasses them. But despite the techno-hype and the national obsession with disruption, the pace of productivity growth has slowed down. The American economy has grown, but largely by adding workers rather than by workers equipping themselves with powerful new machines to multiply their capabilities. And the number of hours worked per worker has stayed relatively flat, even while other countries have continued to enhance their leisure. If robots were taking our jobs, the productivity of the workers who still have jobs — the total amount of work that gets done divided by the total number of people who are employed — would be going up rapidly. But it's not. It  rising, but it's rising   than it did in the past. And the slowing rate of productivity growth is an important source of the wage slowdown that people have been worrying about. The   calculated that if productivity growth had continued at its 1948–1973 pace for the past 40 years, the average household's income would be $30,000 higher today. By contrast, had inequality stayed at its 1973 level for the same period, Obama's Council of Economic Advisers calculates that the average household's income would be only $9,000 higher. The productivity issue is bigger than inequality, in other words. And yet it's much less discussed. In fact, it's almost anti-discussed due to the obsession in media and political circles with the alleged rise of the robots. We're so busy worrying about how to counteract an imaginary, robot-driven productivity surge that we're barely paying attention to the real story of the productivity slowdown. But what about the bounty of digital technology that is in evidence all around us? Almost 30 years ago, the great economist Robert Solow quipped, "You can see the computer age everywhere but in the productivity statistics." An answer to the riddle might be that digital technology has transformed a handful of industries in the media/entertainment space that occupy a mindshare that's out of proportion to their overall economic importance. The robots aren't taking our jobs; they're taking our  . Data from the  , for example, suggests that on average Americans spend about 23 percent of their waking hours watching television, reading, or gaming. With Netflix, HDTV, Kindles, iPads, and all the rest, these are certainly activities that look   different in 2015 than they did in 1995 and can easily create the impression that life has been revolutionized by digital technology. What's more, the media industry itself has been turned upside down by the internet and has spent the last decade telling anyone who will listen how complete and wrenching the transformation has been. That further amplifies a narrative about rapid change. But clearly the media and entertainment industries don't comprise anything close to 23 percent of the workforce or the total economic output of the United States. Most other job categories have been impacted by digital technology, but only in relatively superficial ways. Something like 9 percent of all private sector jobs are in the food service industry. These days people are perhaps more likely to book a reservation or order a takeout meal with an app rather than a phone call, but the core work of serving and preparing food has seen very little progress. At the higher end of the salary spectrum, we still don't have   who can treat patients in lieu of costly and inconvenient human ones. Indeed,  . As it becomes clearer and clearer over time that smartphones and the internet simply aren't economic game changers on the same scale as air conditioning, jet planes, container ships, and televisions, it's become increasingly fashionable in Silicon Valley to simply retreat into denial. "There is a lack of appreciation for what’s happening in Silicon Valley," Google's chief economist,  , "because we don’t have a good way to measure it." The article states that Varian believes a "problem with the government’s productivity measure" is that "it is based on gross domestic product, the tally of goods and services produced by the U.S. economy." But this is not a measurement error. This is the   of economic productivity. When people can create more goods and services for sale in the market economy, their productivity goes up. When they cannot, it does not. It is obviously true that there are things in life that matter that are not monetized in this way. I, personally, derive enormous pleasure from daily jokes on Twitter. That said, Silicon Valley hardly invented the idea that the best things in life are free. The joy that my infant son's smile brings to my face isn't in the GDP numbers either. Nor is the sadness I feel when reflecting on the fact that my late mother didn't live to meet him. But if you want to put a roof over your baby's head, to keep him in diapers and formula, and to buy some plane tickets so he can go with you to visit his grandparents, then you are going to need some  . And money derives from monetized economic activity. The productivity slowdown began decades ago and initially corresponded with bad news from abroad about oil prices. It persisted through a sharp recession that broke the back of inflation, and continued through the Reagan recovery. In the mid- to late 1990s things briefly turned around, and it momentarily looked like the Solow Paradox was gone. Walmart and other big-box stores learned to use computers to better control their inventories and greatly improved the productivity of the retail sector. As is typical with periods of rapid technological change, this led to some displacement and suffering and heartburn. But even though the late '90s were a terrible time to be the owner of a mom-and-pop hardware store,   it was a period of low unemployment and rising wages. But as Paul Krugman has written, "We did not, it turned out, get a sustained return to rapid economic progress. Instead, it was more of a one-time spurt,  ." In the most recent years, it's actually gotten worse than ever.   From a Wells Fargo note: productivity is slumping in nearly every industry    
 
 This extreme slowdown has coincided with a period of weak demand, high unemployment, and agonizingly slow wage growth. That all adds up to an environment in which managers have little budget to invest in new equipment due to weak sales, and little incentive to give raises due to poor worker bargaining power. Rather than hot business trends relating to new equipment that allows workers to deliver more value than ever before, one of the signal trends of our time has been a proliferation of online services that reduce the friction associated with having people get in their car and bring you things. Washio, for example, will send someone to my house to pick up my dry cleaning. Seamless will ping a restaurant and tell it to deliver takeout to my door. Postmates will send someone to get a takeout dinner from a restaurant that doesn't offer delivery. Homejoy will send someone to clean my house. These startups are okay business ideas, but they are not doing anything to advance the efficiency with which clothing is laundered, meals are cooked, or houses are cleaned. The main industry in which productivity is accelerating rapidly is the information technology industry itself. We are getting better and better at making smartphones, apps, cloud services, and all the rest. Those things just aren't driving change in the larger economy. Indeed, the way modern digital technology blurs the lines between entertainment devices and productivity devices in some ways works to   the productivity of the modern office worker. Email means you can stay in touch with remote colleagues, but it also means you can send a note to your dad during business hours. It's clear from the analytics at Vox.com and every other website that America's white-collar workforce is doing a lot of Facebook updates, tweeting, and casual web browsing during business hours. It's surely not a coincidence that 2015's hottest office productivity tool is a group chat service called Slack. This may make life more pleasant in some respects (and annoying in others, as family dinners are now interrupted by random work emails), but it adds up to a remarkably modest impact on the overall health of the economy. Of course, all this   change. The power of Moore's Law — which states that the power of computer chips doubles roughly every two years — is such that the next five years' worth of digital progress will involve bigger leaps in raw processor power than the previous five years. It's at least   that we really will have a massive leap forward in productivity someday soon that starts substantially reducing the amount of human labor needed to drive the economy forward. But robots are never going to take   the jobs.  The problem with trying to envision "a world without work" is that it asks us to envision an unrealistically large change. The more likely outcome is a world with   work. And that's a world we should welcome rather than fear. It's a world in which we can make some policy decisions we want to make, rather than decisions we really   want to make. The "normal" Social Security retirement age in the United States used to be 65. Currently it is moving up to 67. Many prominent politicians, from Jeb Bush and Chris Christie to the bipartisan Simpson-Bowles commission on deficit reduction, say that to keep the system solvent we need to move it up even further, to 70. In a world of more productivity and less work, instead of doing that, we might move it back down to 65. Or maybe even cut it back to 62. Some more ideas: These are just illustrative ideas, of course, not a comprehensive program. But they go to show that given decent public policy, an automation-driven productivity surge is nothing to be afraid of. For any given item on that list, the natural objection will be that "we can't afford it." If productivity accelerated, we could easily afford it — and more — reducing the total amount of human toil while still maintaining the basic life-cycle concept of a career. The real threat is precisely the opposite — that the per-hour productivity of the American worker   increase at a more rapid rate. If you've ever heard a dreary lecture about the "entitlement crisis," that is the world they are talking about. The American population is aging and is projected to continue aging. In other words, the ratio of working-age people to retired people is falling. That means that we will have to either reduce the living standards of the elderly by cutting their benefits, or reduce the living standards of the non-elderly by raising their taxes or cutting spending on programs they depend on. By the same token, the proposition that "health-care costs" will bury the country is essentially the proposition that technology   dramatically increase the productivity of the health-care sector. That means, again, some combination of reduced benefits for the sick and higher premiums and taxes for the healthy. Most likely, we'll keep doing a little bit of both. Unless, that is, some robots come along to help us out. 
 
 